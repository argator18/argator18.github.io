---
layout: default
---
# Chinese Room
The basic experiment is the following:
A human is in a room, together with a huge book full of rules describing how to answer to specific chinese text input.
The he gets some text as input and is supposed to answer folling these rules and output some chinese signs.

### Questions
Does the person in the room understand chinese?

### Interpretation
Obviously the experiment questions the ability of computer to think like human even though producing syntactically correct sentences, like ChatGPT does.


## My take
Obviously the person in this room doesn't understand chinese himself and doesn't understand on a semantically level what he is saying either. 
Still from the POV of an outer spectator, this chinese room passes the turing test as it's output can't be differiantiated from a human who actually speaks chinese.
This room is a black box, that takes chinese input processes it somehow and outputs some chinese sentences.
And this is exactly the same, as other human act for us. We have no knowledge of their internal processes either. All we get is their output.
And as long as the rule set in this book is complex and accurate we can not say if this sentence is produced by a chinese speaking human in the box or a man who applies this set of rules.

Another question that may arise is, if the man in the box is able to infer something about chinese. Will he be able to understand at some point chinese?
This setting can be seen as an unsupervised learning setup. We only have data, but no labels or other feedback. So he will be able to find structures in the design of sentences or similarities between words, but he will never be able to develop an understanding of what the sentences mean in the real world or in his language.

To learn something we need either demonstration or feedback.

This changes if we make another assumption that is neither forbidden nor explicitly allowed in the classical setting.
If we allow the input into the box being dependent on the output, there will be a really high chance to actually develop a reality, that is really close or aligns well with the one from the person that inputs and sees the outputs.

A good example for this concept is Kellen Heller. She was deaf and blind but was still able to learn english and in the end hold speeches.
And she never received any highdimensional input, like sound or image. All she received was touches and sensing input.
While children usually learn a lot through demonstrations, she didn't have that at all.
So the only way she could learn all this, was through feedback. And in her case she was actually never sure, that whatever she did was the correct interpretation. She had to intuietivel assume, that pain is a negative reward and some other type of touch is a positive.

So if the person that handles the input and output would be allowed to depend the next input to the output of the proceeding iteration of the box communication, the person inside would actually be able to learn the language, through abweichen of the ruleset.

What does human make humans?
A lot.
Many would probably say the box differs to human because of a Bewusstsein, a Selbstbewusstsein or Feelings and Emotions, or would argue, that the box always answer the same due to its deterministic nature. But all this are internal things, that we don't even know if other human do have this. We "know" (at least we think we have) that we have all this porperties, but we don't know if anyone else on this planet has the same internal thoughts, emotions and Bewusstsein. So because of the nature of people being blackboxes, we also only see input and output of them, that suggest them to have emotions. So if we integrate in our ruleset words that formulate Feelings and personal or objective experiences this box wouldn't be differentiable from a real human. We could also, even without a source of randomness, extend our algorithm or ruleset to include some index of request/ counter and then produce everytime another response for the same input.
So the only problem in my eyes is the ability to adapt and to learn. So we need to extend the box to be able to change it's ruleset based on the inputs it receives.
And if this adaptation algorithm is useful then we cannot differentiate it from human.
Open Questions:
- can this adaptation algorithm be deterministic and static?
- Is some additional memory needed, or can the ruleset hold all neccessary information if complex enough.

What does human make unique?
Nothing.
There is literally nothing that makes human sth else than objects. We are just a very effective combination of atoms and biochemical processes or a way to create a high entropy and nothing more. There is nothing magical or special about us. And while be might be unique in a huge part of our universe and relatively rare, considered the sparse density of the exisiting of such high functional objects in a random space of random events. 
In an deterministic setting we are exactly in this setting in which we are able to get created, and in an undeterministic setting, we are probably produces many times.

Before I argued, why from on outer perspective we human and the box or both blackboxes that can't be differentiated and it a ruleset wouldn't differ to some selbstbewusst higher understanding Wesen, like the man in the box, or some soul, full of emotions feeling and "understanding" of the real world.

By the way there is no "understanding". There is a reality of first order and every person has a reality of second order, that sometimes aligns well with the realities of other person and sometimes it doesn't.

### Is there a man in the room?
Further I would argue, that there is no man in the room. All critique to the comparison between human and the chinese room, tries to argue that the man in the room not really understands or can reflect it's own experiences or internal being like how he feels.
But in my opinion there is no man required to execute the rules, but rather a cpu would do it as well. Further even people are only executing some very complex ruleset (based on at least 7 inputs and some priors).
We really are defined through the input we get. We are no high understanding Wesen, that processes the input understands it in a higher level and gives an output without any ruleset. We are exactly that, a ruleset.
We learned it over the time. But the language e.g. is what defines us as human beings. African people with indigenous languages without specific numbers, are not able to calculate at all. And this even though they fully "understand" their language. But as they never required it and their language doesn't consider these nubmers, they as a higher understanding person behind the language understanding still doens't understand what it means to add 3 and 3.
So you cannot see the "understanding" without langauge. Cause language is really the only way to understnad. There is some lower ruleset we follow.




Syntax vs Semantic

Information theory

Determinism
Free will
